# Full_dataset(NODATA = Ocean)
# Trial 1-10360/10360 - 3180s 307ms/step - loss: 0.6393 - acc: 0.7522 - val_loss: 0.7298 - val_acc: 0.7062

# Clean_NODATA
# Trial 1 - 9810/9810 - 3317s 338ms/step - loss: 0.6377 - acc: 0.6956 - val_loss: 0.4913 - val_acc: 0.7976
# Trial 2 - 9810/9810 - 3194s 326ms/step - loss: 0.6272 - acc: 0.7472 - val_loss: 0.5139 - val_acc: 0.7846

# Clean_NODATA UNet_v2 reshape normalization_max
# Trial 1 - 9810/9810 - 3170s 323ms/step - loss: 0.5399 - acc: 0.7710 - val_loss: 0.4679 - val_acc: 0.8018
# Trial 2 - 9810/9810 - 3154s 322ms/step - loss: 0.5501 - acc: 0.7649 - val_loss: 0.4657 - val_acc: 0.8027

# Clean_NODATA UNet_v2 no_reshape normalization_max
# Trial 1 - 9810/9810 - 3170s 323ms/step - loss: 0.5435 - acc: 0.7694 - val_loss: 0.4792 - val_acc: 0.7990
# Trial 2 - 9810/9810 - 3177s 324ms/step - loss: 0.5464 - acc: 0.7675 - val_loss: 0.4807 - val_acc: 0.7965
# Trial 3 - 9810/9810 - 3170s 323ms/step - loss: 0.5417 - acc: 0.7704 - val_loss: 0.4703 - val_acc: 0.8014
# Trial 4 - 9810/9810 - 3182s 324ms/step - loss: 0.5464 - acc: 0.7684 - val_loss: 0.4701 - val_acc: 0.8009

# Clean_NODATA UNet_v2 no_reshape normalization_max_[-1,1]
# Trial 1 - 9810/9810 - 3158s 322ms/step - loss: 0.6137 - acc: 0.7487 - val_loss: 0.5273 - val_acc: 0.7776
# Trial 2 - 9810/9810 - 3159s 322ms/step - loss: 0.6204 - acc: 0.7443 - val_loss: 1.2169 - val_acc: 0.4579

# Clean_NODATA UNet_v2 no_reshape normalization_mean_std
# Trial 1 - 9810/9810 - 3153s 321ms/step - loss: 0.5213 - acc: 0.7912 - val_loss: 0.4634 - val_acc: 0.8070
# Trial 2 - 9810/9810 - 3228s 329ms/step - loss: 0.5134 - acc: 0.7936 - val_loss: 0.4506 - val_acc: 0.8130
# Trial 3 - 9810/9810 - 3196s 326ms/step - loss: 0.5191 - acc: 0.7922 - val_loss: 0.4612 - val_acc: 0.8084

# Clean_NODATA UNet_v2 no_reshape normalization_mean_std batches_2
# Trial 1 - 4905/4905 - 2515s 513ms/step - loss: 0.5211 - acc: 0.7910 - val_loss: 0.4677 - val_acc: 0.8041
# Trial 2 - 4905/4905 - 2516s 513ms/step - loss: 0.5180 - acc: 0.7931 - val_loss: 0.4715 - val_acc: 0.8035
# Trial 3 - 4905/4905 - 2537s 517ms/step - loss: 0.5234 - acc: 0.7909 - val_loss: 0.4812 - val_acc: 0.7961

# Clean_NODATA UNet_v2 no_reshape normalization_mean_std batches_4
# Trial 1 - 2453/2453 - 2185s 891ms/step - loss: 0.5350 - acc: 0.7865 - val_loss: 0.4995 - val_acc: 0.7894
# Trial 2 - 2453/2453 - 2183s 890ms/step - loss: 0.5241 - acc: 0.7932 - val_loss: 0.4863 - val_acc: 0.7962
# Trial 3 - 2453/2453 - 2186s 891ms/step - loss: 0.5263 - acc: 0.7916 - val_loss: 0.4901 - val_acc: 0.7932
# Trial 4 - 2453/2453 - 2149s 876ms/step - loss: 0.5285 - acc: 0.7899 - val_loss: 0.4947 - val_acc: 0.7890


# Clean_NODATA UNet_v2 no_reshape normalization_mean_std batches_5
# Trial 1 - 1962/1962 - 2135s 1s/step - loss: 0.5336 - acc: 0.7865 - val_loss: 0.4938 - val_acc: 0.7916
# Trial 2 - 1962/1962 - 2151s 1s/step - loss: 0.5347 - acc: 0.7875 - val_loss: 0.4965 - val_acc: 0.7884

#### Desktop computer Diogo's station ###

# Clean_NODATA UNet_v3 no_reshape normalization_mean_std batches_4 batch_normalization
# Trial 1 - 2453/2453 - 986s 402ms/step - loss: 0.6384 - acc: 0.7634 - val_loss: 0.4791 - val_acc: 0.8085

# Clean_NODATA UNet_v3 no_reshape normalization_mean_std batches_4 batch_normalization epochs_2
# Trial 1   Epoch1 - 2453/2453 - 992s 405ms/step - loss: 0.5936 - acc: 0.7666 - val_loss: 0.4929 - val_acc: 0.8004
#           Epoch2 - 2453/2453 - 982s 400ms/step - loss: 0.4754 - acc: 0.8070 - val_loss: 0.4506 - val_acc: 0.8154

# Clean_NODATA UNet_v3 no_reshape normalization_mean_std batches_8 batch_normalization
# Trial 1 - 1227/1227 - 932s 760ms/step - loss: 0.6186 - acc: 0.7735 - val_loss: 0.4723 - val_acc: 0.8137

# Clean_NODATA UNet_v3 no_reshape normalization_mean_std batches_8 batch_normalization epochs_3
# Trial 1   Epoch1 - 1227/1227 - 896s 730ms/step - loss: 0.6179 - acc: 0.7768 - val_loss: 0.4769 - val_acc: 0.8163
#           Epoch2 - 1227/1227 - 884s 720ms/step - loss: 0.4806 - acc: 0.8090 - val_loss: 0.4407 - val_acc: 0.8236
#           Epoch3 - 1227/1227 - 884s 720ms/step - loss: 0.4411 - acc: 0.8222 - val_loss: 0.4285 - val_acc: 0.8251

# Trial 2   Epoch1 - 1227/1227 - 969s 790ms/step - loss: 0.5856 - acc: 0.7792 - val_loss: 0.4823 - val_acc: 0.8077
#           Epoch2 - 1227/1227 - 885s 721ms/step - loss: 0.4727 - acc: 0.8103 - val_loss: 0.4554 - val_acc: 0.8247
#           Epoch3 - 1227/1227 - 883s 720ms/step - loss: 0.4399 - acc: 0.8221 - val_loss: 0.4233 - val_acc: 0.8297

# Clean_NODATA UNet_v3 no_reshape normalization_mean_std batches_6 batch_normalization epochs_6
# Trial 1   Epoch1 - 1635/1635 - 927s 567ms/step - loss: 0.5784 - acc: 0.7772 - val_loss: 0.4935 - val_acc: 0.8031
#           Epoch2 - 1635/1635 - 917s 561ms/step - loss: 0.4741 - acc: 0.8089 - val_loss: 0.4705 - val_acc: 0.8153
#           Epoch3 - 1635/1635 - 917s 561ms/step - loss: 0.4401 - acc: 0.8214 - val_loss: 0.4182 - val_acc: 0.8298
#           Epoch4 - 1635/1635 - 917s 561ms/step - loss: 0.4191 - acc: 0.8292 - val_loss: 0.4172 - val_acc: 0.8321
#           Epoch5 - 1635/1635 - 917s 561ms/step - loss: 0.4040 - acc: 0.8351 - val_loss: 0.4071 - val_acc: 0.8364
#           Epoch6 - 1635/1635 - 917s 561ms/step - loss: 0.3917 - acc: 0.8399 - val_loss: 0.3975 - val_acc: 0.8395

# Clean_NODATA UNet_v3 no_reshape normalization_mean_std batches_8 batch_normalization epochs_40
#           Epoch01 - 1227/1227 - 894s 729ms/step - loss: 0.5902 - acc: 0.7784 - val_loss: 0.5019 - val_acc: 0.8154
#           Epoch05 - 1227/1227 - 884s 720ms/step - loss: 0.3984 - acc: 0.8378 - val_loss: 0.3991 - val_acc: 0.8329
#           Epoch35 - 1227/1227 - 883s 719ms/step - loss: 0.2180 - acc: 0.9128 - val_loss: 0.4080 - val_acc: 0.8539
#           Epoch40 - 1227/1227 - 912s 744ms/step - loss: 0.1985 - acc: 0.9203 - val_loss: 0.4430 - val_acc: 0.8502

# Clean_NODATA UNet_v3 no_reshape normalization_mean_std batches_8 batch_normalization epochs_6
# Trial 1   Epoch1 - 1227/1227 - 925s 754ms/step - loss: 0.5963 - acc: 0.7794 - val_loss: 0.4829 - val_acc: 0.8173
#           Epoch2 - 1227/1227 - 884s 721ms/step - loss: 0.4731 - acc: 0.8108 - val_loss: 0.4418 - val_acc: 0.8166
# Trial 2   Epoch1 - 1227/1227 - 895s 730ms/step - loss: 0.5533 - acc: 0.7817 - val_loss: 0.4594 - val_acc: 0.8120
#           Epoch2 - 1227/1227 - 886s 722ms/step - loss: 0.4652 - acc: 0.8111 - val_loss: 0.4253 - val_acc: 0.8245

# Clean_NODATA UNet_v5 normalization_mean_std batches_8 no_batch_normalization transpose_convolution augmentation epochs_10
# 252x252_164x164
# Trial 1   Epoch01 - 1227/1227 - 925s 753ms/step - loss: 0.5709 - acc: 0.7749 - val_loss: 0.5290 - val_acc: 0.7773
#           Epoch02 - 1227/1227 - 423s 344ms/step - loss: 0.4901 - acc: 0.7997 - val_loss: 0.4693 - val_acc: 0.8024
#           Epoch04 - 1227/1227 - 420s 343ms/step - loss: 0.4350 - acc: 0.8200 - val_loss: 0.4602 - val_acc: 0.8061
#           Epoch06 - 1227/1227 - 421s 343ms/step - loss: 0.4085 - acc: 0.8308 - val_loss: 0.4283 - val_acc: 0.8176
#           Epoch08 - 1227/1227 - 422s 344ms/step - loss: 0.3936 - acc: 0.8366 - val_loss: 0.4052 - val_acc: 0.8274
#           Epoch10 - 1227/1227 - 423s 345ms/step - loss: 0.3808 - acc: 0.8419 - val_loss: 0.3968 - val_acc: 0.8329

# Clean_NODATA UNet_v5 normalization_mean_std batches_8 batch_normalization transpose_convolution augmentation epochs_20
# 252x252_164x164
# Trial 1   Epoch01 - 1227/1227 - 428s 349ms/step - loss: 0.6254 - acc: 0.7695 - val_loss: 0.4809 - val_acc: 0.8052
#           Epoch05 - 1227/1227 - 422s 344ms/step - loss: 0.4268 - acc: 0.8255 - val_loss: 0.4232 - val_acc: 0.8227
#           Epoch10 - 1227/1227 - 423s 345ms/step - loss: 0.3857 - acc: 0.8409 - val_loss: 0.4042 - val_acc: 0.8285
#           Epoch15 - 1227/1227 - 424s 346ms/step - loss: 0.3638 - acc: 0.8498 - val_loss: 0.3852 - val_acc: 0.8348
#           Epoch20 - 1227/1227 - 421s 343ms/step - loss: 0.3491 - acc: 0.8558 - val_loss: 0.3861 - val_acc: 0.8363

# Clean_NODATA UNet_v5 normalization_max batches_6 batch_normalization transpose_convolution augmentation epochs_40
# 252x252_164x164
# Trial 1   Epoch01 - 1635/1635 - 892s 545ms/step - loss: 0.6274 - acc: 0.7588 - val_loss: 0.5019 - val_acc: 0.7993
#           Epoch10 - 1635/1635 - 418s 256ms/step - loss: 0.4058 - acc: 0.8322 - val_loss: 0.4071 - val_acc: 0.8311
#           Epoch20 - 1635/1635 - 417s 255ms/step - loss: 0.3631 - acc: 0.8499 - val_loss: 0.3869 - val_acc: 0.8396
#           Epoch30 - 1635/1635 - 420s 257ms/step - loss: 0.3380 - acc: 0.8608 - val_loss: 0.3764 - val_acc: 0.8450
#           Epoch40 - 1635/1635 - 418s 256ms/step - loss: 0.3167 - acc: 0.8698 - val_loss: 0.4053 - val_acc: 0.8403

# Clean_NODATA UNet_v5 normalization_mean_std batches_6 batch_normalization transpose_convolution augmentation epochs_40
# 252x252_164x164
# Epoch 40 - 1635/1635 - 438s 268ms/step - loss: 0.3163 - acc: 0.8704 - val_loss: 0.4124 - val_acc: 0.8416
############################ Predictions ####################################### Classification Report #############
############           Artificiais|Agrícola|Floresta||Húmidas|||||Água  # Precision    Recall  f1-score   Support ##
############ Artificiais[[  232155  2670278     2057      893   610106] #      0.13      0.07      0.09   3515489 ##
############    Agrícola [  686982 22557457   103530    15446  2238300] #      0.50      0.88      0.64  25601715 ##
## Ground ##    Floresta [  877841 19521483   442422    57823 14941468] #      0.81      0.01      0.02  35841037 ##
## Truth  ##     Húmidas [     143    23987       59        0   114900] #      0.00      0.00      0.00    139089 ##
############        Água [    6334    36684      283       69   835188]]#      0.04      0.95      0.09    878558 ##
##########################################################     accuracy #                          0.36  65975888 ##
##########################################################    macro avg #      0.30      0.38      0.17  65975888 ##
########################################################## weighted avg #      0.64      0.36      0.27  65975888 ##
####################################################################################################################

# Clean_NODATA UNet_v5 normalization_mean_std batches_8 no_batch_normalization transpose_convolution augmentation epochs_10
# 252x252_164x164 NO B09 & B10
# Epoch10 - 1227/1227 - 377s 307ms/step - loss: 0.3806 - acc: 0.8418 - val_loss: 0.4083 - val_acc: 0.8295
############################ Predictions ####################################### Classification Report #############
############           Artificiais|Agrícola|Floresta||Húmidas|||||Água  # Precision    Recall  f1-score   Support ##
############ Artificiais[[ 1466985   681647  1274223    83385     9249] #      0.63      0.42      0.50   3515489 ##
############    Agrícola [  385610 13245161 11941519    22995     6430] #      0.82      0.52      0.63  25601715 ##
## Ground ##    Floresta [  392918  2273324 32714828   453379     6588] #      0.71      0.91      0.80  35841037 ##
## Truth  ##     Húmidas [   13009     1218    58728    65477      657] #      0.05      0.47      0.09    139089 ##
############        Água [   87137    40182    47906   672063    31270]]#      0.58      0.04      0.07    878558 ##
##########################################################     accuracy #                          0.72  65975888 ##
##########################################################    macro avg #      0.56      0.47      0.42  65975888 ##
########################################################## weighted avg #      0.74      0.72      0.71  65975888 ##
####################################################################################################################

clean_NODATA: YES
num_classes: 5
channels: ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B8A','B09', 'B10', 'B11']
UNet: v5
reshape: 252->164
normalization: mean_std
batch_normalization: NO
transpose_convolution: YES
augmentation: YES
batches: 8
epochs: 100
Results:
# Epoch100 - 1227/1227 - 374s 305ms/step - loss: 0.2424 - acc: 0.9010 - val_loss: 0.3778 - val_acc: 0.8571
############################ Predictions ####################################### Classification Report #############
############           Artificiais|Agrícola|Floresta||Húmidas|||||Água  # Precision    Recall  f1-score   Support ##
############ Artificiais[[ 2570262   560695   375681     3374     5477] #      0.32      0.73      0.44   3515489 ##
############    Agrícola [ 1677164 15019247  8714078     1306   189920] #      0.70      0.59      0.64  25601715 ##
## Ground ##    Floresta [ 3547100  5826680 26372954     9158    85145] #      0.74      0.74      0.74  35841037 ##
## Truth  ##     Húmidas [   57476    18667    21755    34086     7105] #      0.10      0.25      0.14    139089 ##
############        Água [  258603   146402    96564   297869    79120]]#      0.22      0.09      0.13    878558 ##
##########################################################     accuracy #                          0.67  65975888 ##
##########################################################    macro avg #      0.41      0.48      0.42  65975888 ##
########################################################## weighted avg #      0.69      0.67      0.67  65975888 ##
####################################################################################################################

clean_NODATA: YES
num_classes: 5
channels: ['B02', 'B03', 'B04']
UNet: v5
reshape: 252->164
normalization: mean_std
batch_normalization: NO
transpose_convolution: YES
augmentation: YES
batches: 8
epochs: 10
Results:
# Epoch01 - 1227/1227 - 286s 233ms/step - loss: 0.6425 - acc: 0.7439 - val_loss: 0.5855 - val_acc: 0.7656
# Epoch05 - 1227/1227 - 280s 228ms/step - loss: 0.4631 - acc: 0.8089 - val_loss: 0.5209 - val_acc: 0.7745
# Epoch10 - 1227/1227 - 279s 227ms/step - loss: 0.4171 - acc: 0.8280 - val_loss: 0.4595 - val_acc: 0.8045
############################ Predictions ####################################### Classification Report #############
############           Artificiais|Agrícola|Floresta||Húmidas|||||Água  # Precision    Recall  f1-score   Support ##
############ Artificiais[[ 1919638   895001   635909    10123    54818] #      0.83      0.55      0.66   3515489 ##
############    Agrícola [  261169 16806744  8505110      157    28535] #      0.85      0.66      0.74  25601715 ##
## Ground ##    Floresta [  125888  1929914 33758353      128    26754] #      0.78      0.94      0.86  35841037 ##
## Truth  ##     Húmidas [    1165    28112    58580    16072    35160] #      0.26      0.12      0.16    139089 ##
############        Água [   11018   149380   107345    34320   576495]]#      0.80      0.66      0.72    878558 ##
##########################################################     accuracy #                          0.80  65975888 ##
##########################################################    macro avg #      0.70      0.58      0.63  65975888 ##
########################################################## weighted avg #      0.81      0.80      0.80  65975888 ##
####################################################################################################################

clean_NODATA: YES
num_classes: 4
channels: ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B10', 'B12']
UNet: v5
reshape: 252->164
normalization: mean_std
batch_normalization: NO
transpose_convolution: YES
augmentation: YES
batches: 8
epochs: 10
Results:
# Epoch10 - 1227/1227 - 410s 334ms/step - loss: 0.3842 - acc: 0.8421 - val_loss: 0.3954 - val_acc: 0.8346
############################ Predictions ############################## Classification Report #############
############           Artificiais|Agrícola|Floresta|||||Água  # Precision    Recall  f1-score   Support ##
############ Artificiais[[ 2305265   676968   437687     3893] #      0.77      0.66      0.71   3515489 ##
############    Agrícola [  405198 20024231  5150490     2578] #      0.82      0.78      0.80  25601715 ##
## Ground ##    Floresta [  221182  3605487 31976278     5276] #      0.85      0.89      0.87  35841037 ##
## Truth  ##        Água [    9636    16780    28127    43756] #      0.45      0.31      0.37    139089 ##
#################################################    micro avg #      0.84      0.83      0.84  65975888 ##
#################################################    macro avg #      0.72      0.66      0.69  65975888 ##
################################################# weighted avg #      0.83      0.83      0.83  65975888 ##
###########################################################################################################

ALL CLASSES
clean_NODATA: YES
num_classes: 47
channels: ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A','B09', 'B10', 'B11', 'B12']
UNet: v5
reshape: 252->164
normalization: mean_std
batch_normalization: YES
transpose_convolution: YES
augmentation: YES
batches: 8
epochs: 20
EPOCH20 - loss: 1.4552 - acc: 0.5488 - val_loss: 1.5762 - val_acc: 0.5126